{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d997ec0-1776-43e5-a0a9-eefa4c10a769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0896a8b5-9bc2-4b42-85c7-6b28c6309fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Life is short, eat dessert first'\n",
    "\n",
    "mapping = {s: i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c4b0b9-322f-44de-b585-c2a282fb4e26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 5, 2, 1, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_int = torch.tensor([mapping[s] for s in sentence.replace(',','').split()])\n",
    "sentence_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a35d3af-0d8c-4dc4-8912-668bb2c9e7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035],\n",
      "        [ 0.1794,  1.8951,  0.4954],\n",
      "        [ 0.2692, -0.0770, -1.0205],\n",
      "        [-0.2196, -0.3792,  0.7671],\n",
      "        [-0.5880,  0.3486,  0.6603],\n",
      "        [-1.1925,  0.6984, -1.4097]])\n",
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 50_000\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(vocab_size, 3)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5797cedb-98da-40a9-ac94-1624435ed3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(124)\n",
    "\n",
    "d = embedded_sentence.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f3ae1e-da82-4c60-a401-e4f6c49e2b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.7310, 0.4033, 0.5970],\n",
       "         [0.3808, 0.7053, 0.0211]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5950, 0.7909, 0.0994],\n",
       "         [0.1674, 0.3942, 0.0355],\n",
       "         [0.5912, 0.3594, 0.2125],\n",
       "         [0.0139, 0.6765, 0.3368]], requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_q, d_k, d_v = 2, 2, 4\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))\n",
    "\n",
    "W_query, W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99873cf8-5d28-4a17-9369-8d3f58ffa7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query @ x_2\n",
    "key_2 = W_key @ x_2\n",
    "value_2 = W_value @ x_2\n",
    "\n",
    "print(query_2.shape)\n",
    "print(key_2.shape)\n",
    "print(value_2.shape)\n",
    "\n",
    "query_2, key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc01ef4b-75b2-4722-9216-ab8a73a11442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0300, -0.0029],\n",
       "        [ 1.5483,  0.7627],\n",
       "        [-0.5884, -0.0187],\n",
       "        [ 0.1944, -0.1504],\n",
       "        [ 0.1739,  0.0260],\n",
       "        [-1.7673, -0.0923]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = embedded_sentence @ W_key.T\n",
    "values = embedded_sentence @ W_value.T\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acd46679-e413-43ab-8f71-debee11ab151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0398,  2.9238, -0.7273,  0.0188,  0.2440, -2.2358],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_2 = query_2 @ keys.T\n",
    "omega_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b54ba93-7bdd-42e7-b06b-41d9cb5f94c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: sympy in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: filelock in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: networkx in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/snewcomer/miniconda3/envs/ab/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "259febca-4435-42d5-919e-b0698ab1d533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0818, 0.6652, 0.0503, 0.0853, 0.1000, 0.0173],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=-1)\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f14a728-8ff7-4909-a45c-97617fbb004e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0670, 0.5186, 0.5652, 0.9726], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2 @ values\n",
    "context_vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23d65981-6d14-4759-8471-d992e20cac27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        omega = queries @ keys.T\n",
    "        print(omega / d_out_kq ** 0.5)\n",
    "        attention_weights = F.softmax(omega / d_out_kq ** 0.5, dim=-1)\n",
    "        \n",
    "        return attention_weights @ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eac4aa5c-075d-4406-a072-c4b4bf636421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0434, -0.2469,  0.1020, -0.0309, -0.0921,  0.0761],\n",
      "        [-0.4246,  2.4542, -1.0623,  0.3529,  0.9124, -0.9456],\n",
      "        [ 0.1720, -0.9853,  0.4150, -0.1309, -0.3671,  0.3345],\n",
      "        [-0.0562,  0.3173, -0.1278,  0.0366,  0.1186, -0.0846],\n",
      "        [-0.1068,  0.6100, -0.2544,  0.0786,  0.2274, -0.1971],\n",
      "        [ 0.3072, -1.7704,  0.7594, -0.2481, -0.6587,  0.6551]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1564,  0.1028, -0.0763, -0.0764],\n",
      "        [ 0.5313,  1.3607,  0.7891,  1.3110],\n",
      "        [-0.3542, -0.1234, -0.2627, -0.3706],\n",
      "        [ 0.0071,  0.3345,  0.0969,  0.1998],\n",
      "        [ 0.1008,  0.4780,  0.2021,  0.3674],\n",
      "        [-0.5296, -0.2799, -0.4107, -0.6006]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# reduce d_out_v from 4 to 1, because we have 4 heads\n",
    "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
    "\n",
    "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
    "print(sa(embedded_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9fa4e-78fc-4b12-8c8c-e298fe94a4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b6ae6-ba16-41b0-ac3e-3501f7f4dba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a143ed-87fb-498e-8793-c196e16142da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
